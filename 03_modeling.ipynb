{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc9cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "#import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d152ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasketballPredictiveModels:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.feature_importance = {}\n",
    "        self.performance_metrics = {}\n",
    "        \n",
    "    def prepare_efficiency_target(self, df, target_metric='ADV_EFF'):\n",
    "        \"\"\"Prepare target variable for efficiency prediction\"\"\"\n",
    "        # Create forward-looking efficiency target (next game or period)\n",
    "        df_sorted = df.sort_values(['PLAYER_ID', 'GAME_DATE']) if 'GAME_DATE' in df.columns else df\n",
    "        \n",
    "        if 'PLAYER_ID' in df.columns:\n",
    "            df_sorted['FUTURE_EFF'] = df_sorted.groupby('PLAYER_ID')[target_metric].shift(-1)\n",
    "        else:\n",
    "            df_sorted['FUTURE_EFF'] = df_sorted[target_metric]\n",
    "        \n",
    "        # Remove rows with missing targets\n",
    "        df_clean = df_sorted.dropna(subset=['FUTURE_EFF'])\n",
    "        \n",
    "        return df_clean\n",
    "    \n",
    "    def build_efficiency_models(self, X, y, test_size=0.2):\n",
    "        \"\"\"Build multiple models to predict player efficiency\"\"\"\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Define models\n",
    "        models_to_train = {\n",
    "            'random_forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "            'xgboost': xgb.XGBRegressor(n_estimators=100, random_state=42),\n",
    "            'gradient_boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "            'elastic_net': ElasticNet(alpha=0.1, random_state=42),\n",
    "            'lightgbm': lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1)\n",
    "        }\n",
    "        \n",
    "        # Train and evaluate each model\n",
    "        for name, model in models_to_train.items():\n",
    "            print(f\"Training {name}...\")\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            train_pred = model.predict(X_train)\n",
    "            test_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "            test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
    "            test_mae = mean_absolute_error(y_test, test_pred)\n",
    "            test_r2 = r2_score(y_test, test_pred)\n",
    "            \n",
    "            # Store results\n",
    "            self.models[name] = model\n",
    "            self.performance_metrics[name] = {\n",
    "                'train_rmse': train_rmse,\n",
    "                'test_rmse': test_rmse,\n",
    "                'test_mae': test_mae,\n",
    "                'test_r2': test_r2\n",
    "            }\n",
    "            \n",
    "            # Store feature importance if available\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                self.feature_importance[name] = model.feature_importances_\n",
    "        \n",
    "        return X_test, y_test\n",
    "    \n",
    "    def optimize_best_model(self, X, y, cv_folds=5):\n",
    "        \"\"\"Hyperparameter tuning for the best performing model\"\"\"\n",
    "        # Find best model based on test RMSE\n",
    "        best_model_name = min(self.performance_metrics.keys(), \n",
    "                            key=lambda x: self.performance_metrics[x]['test_rmse'])\n",
    "        \n",
    "        print(f\"Optimizing {best_model_name}...\")\n",
    "        \n",
    "        # Define parameter grids\n",
    "        param_grids = {\n",
    "            'random_forest': {\n",
    "                'n_estimators': [100, 200, 300],\n",
    "                'max_depth': [10, 15, 20, None],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4]\n",
    "            },\n",
    "            'xgboost': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [3, 5, 7],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'subsample': [0.8, 0.9, 1.0]\n",
    "            },\n",
    "            'gradient_boosting': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [3, 5, 7],\n",
    "                'learning_rate': [0.01, 0.1, 0.2]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if best_model_name in param_grids:\n",
    "            # Get base model\n",
    "            if best_model_name == 'random_forest':\n",
    "                base_model = RandomForestRegressor(random_state=42)\n",
    "            elif best_model_name == 'xgboost':\n",
    "                base_model = xgb.XGBRegressor(random_state=42)\n",
    "            elif best_model_name == 'gradient_boosting':\n",
    "                base_model = GradientBoostingRegressor(random_state=42)\n",
    "            \n",
    "            # Grid search\n",
    "            grid_search = GridSearchCV(\n",
    "                base_model, \n",
    "                param_grids[best_model_name],\n",
    "                cv=cv_folds,\n",
    "                scoring='neg_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X, y)\n",
    "            \n",
    "            # Update best model\n",
    "            self.models[f'{best_model_name}_optimized'] = grid_search.best_estimator_\n",
    "            \n",
    "            print(f\"Best parameters for {best_model_name}: {grid_search.best_params_}\")\n",
    "            \n",
    "            return grid_search.best_estimator_\n",
    "        \n",
    "        return self.models[best_model_name]\n",
    "    \n",
    "    def predict_player_efficiency(self, player_features, model_name='random_forest'):\n",
    "        \"\"\"Predict efficiency for new player data\"\"\"\n",
    "        if model_name not in self.models:\n",
    "            raise ValueError(f\"Model {model_name} not found. Available models: {list(self.models.keys())}\")\n",
    "        \n",
    "        model = self.models[model_name]\n",
    "        predictions = model.predict(player_features)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def get_feature_importance(self, feature_names, model_name='random_forest', top_n=20):\n",
    "        \"\"\"Get and visualize feature importance\"\"\"\n",
    "        if model_name not in self.feature_importance:\n",
    "            print(f\"Feature importance not available for {model_name}\")\n",
    "            return None\n",
    "        \n",
    "        # Create importance dataframe\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': self.feature_importance[model_name]\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        # Plot top features\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.barplot(data=importance_df.head(top_n), y='feature', x='importance')\n",
    "        plt.title(f'Top {top_n} Feature Importance - {model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return importance_df\n",
    "    \n",
    "    def save_models(self, filepath_prefix='basketball_models'):\n",
    "        \"\"\"Save trained models\"\"\"\n",
    "        for name, model in self.models.items():\n",
    "            joblib.dump(model, f\"{filepath_prefix}_{name}.pkl\")\n",
    "        \n",
    "        # Save performance metrics\n",
    "        pd.DataFrame(self.performance_metrics).T.to_csv(f\"{filepath_prefix}_performance.csv\")\n",
    "        \n",
    "        print(\"Models saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f77c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your processed data\n",
    "df = pd.read_csv('processed_player_data.csv')\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = BasketballPredictiveModels()\n",
    "\n",
    "# Prepare target variable\n",
    "df_with_target = predictor.prepare_efficiency_target(df)\n",
    "\n",
    "# Prepare features\n",
    "feature_cols = [col for col in df_with_target.columns \n",
    "               if col not in ['FUTURE_EFF', 'PLAYER_NAME', 'TEAM_ABBREVIATION']]\n",
    "\n",
    "X = df_with_target[feature_cols]\n",
    "y = df_with_target['FUTURE_EFF']\n",
    "\n",
    "# Build models\n",
    "X_test, y_test = predictor.build_efficiency_models(X, y)\n",
    "\n",
    "# Optimize best model\n",
    "best_model = predictor.optimize_best_model(X, y)\n",
    "\n",
    "# Show results\n",
    "for model_name, metrics in predictor.performance_metrics.items():\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"  {metric_name}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
